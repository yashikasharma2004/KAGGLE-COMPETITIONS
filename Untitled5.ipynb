{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt4tEAsBVAhp",
        "outputId": "f610bd59-6d3e-497f-a2eb-2aa795028656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 15475.08865341\n",
            "Validation score: -35.845870\n",
            "Iteration 2, loss = 14152.41904698\n",
            "Validation score: -30.868783\n",
            "Iteration 3, loss = 11289.85791056\n",
            "Validation score: -20.844520\n",
            "Iteration 4, loss = 6268.63838040\n",
            "Validation score: -6.566689\n",
            "Iteration 5, loss = 1176.92693967\n",
            "Validation score: 0.671063\n",
            "Iteration 6, loss = 501.25107877\n",
            "Validation score: 0.168215\n",
            "Iteration 7, loss = 184.98719864\n",
            "Validation score: 0.787060\n",
            "Iteration 8, loss = 124.25842973\n",
            "Validation score: 0.720434\n",
            "Iteration 9, loss = 75.77316692\n",
            "Validation score: 0.876464\n",
            "Iteration 10, loss = 63.27929204\n",
            "Validation score: 0.879782\n",
            "Iteration 11, loss = 51.77193545\n",
            "Validation score: 0.882605\n",
            "Iteration 12, loss = 47.54826269\n",
            "Validation score: 0.890318\n",
            "Iteration 13, loss = 42.93791048\n",
            "Validation score: 0.901163\n",
            "Iteration 14, loss = 39.96335315\n",
            "Validation score: 0.903232\n",
            "Iteration 15, loss = 36.64525521\n",
            "Validation score: 0.905757\n",
            "Iteration 16, loss = 33.95322216\n",
            "Validation score: 0.910440\n",
            "Iteration 17, loss = 31.46097597\n",
            "Validation score: 0.914778\n",
            "Iteration 18, loss = 29.20217852\n",
            "Validation score: 0.917974\n",
            "Iteration 19, loss = 27.19367543\n",
            "Validation score: 0.919901\n",
            "Iteration 20, loss = 25.27122745\n",
            "Validation score: 0.923710\n",
            "Iteration 21, loss = 23.56824574\n",
            "Validation score: 0.926708\n",
            "Iteration 22, loss = 21.96766021\n",
            "Validation score: 0.929375\n",
            "Iteration 23, loss = 20.52213538\n",
            "Validation score: 0.932147\n",
            "Iteration 24, loss = 19.27948264\n",
            "Validation score: 0.933739\n",
            "Iteration 25, loss = 18.02422717\n",
            "Validation score: 0.936350\n",
            "Iteration 26, loss = 16.96469756\n",
            "Validation score: 0.938165\n",
            "Iteration 27, loss = 15.86474685\n",
            "Validation score: 0.940546\n",
            "Iteration 28, loss = 14.94854007\n",
            "Validation score: 0.942553\n",
            "Iteration 29, loss = 14.04512265\n",
            "Validation score: 0.943938\n",
            "Iteration 30, loss = 13.22643317\n",
            "Validation score: 0.945815\n",
            "Iteration 31, loss = 12.48086431\n",
            "Validation score: 0.948184\n",
            "Iteration 32, loss = 11.75321927\n",
            "Validation score: 0.949488\n",
            "Iteration 33, loss = 11.05762198\n",
            "Validation score: 0.950490\n",
            "Iteration 34, loss = 10.49040244\n",
            "Validation score: 0.951977\n",
            "Iteration 35, loss = 9.92602817\n",
            "Validation score: 0.953674\n",
            "Iteration 36, loss = 9.44350695\n",
            "Validation score: 0.954687\n",
            "Iteration 37, loss = 8.93824670\n",
            "Validation score: 0.956651\n",
            "Iteration 38, loss = 8.49489867\n",
            "Validation score: 0.957102\n",
            "Iteration 39, loss = 8.08168238\n",
            "Validation score: 0.958184\n",
            "Iteration 40, loss = 7.70534031\n",
            "Validation score: 0.959489\n",
            "Iteration 41, loss = 7.32943492\n",
            "Validation score: 0.959955\n",
            "Iteration 42, loss = 7.02414213\n",
            "Validation score: 0.961145\n",
            "Iteration 43, loss = 6.68194130\n",
            "Validation score: 0.961947\n",
            "Iteration 44, loss = 6.40455800\n",
            "Validation score: 0.962781\n",
            "Iteration 45, loss = 6.15261448\n",
            "Validation score: 0.963660\n",
            "Iteration 46, loss = 5.91233699\n",
            "Validation score: 0.964149\n",
            "Iteration 47, loss = 5.64128604\n",
            "Validation score: 0.964868\n",
            "Iteration 48, loss = 5.42255046\n",
            "Validation score: 0.965750\n",
            "Iteration 49, loss = 5.18977721\n",
            "Validation score: 0.966189\n",
            "Iteration 50, loss = 5.02310498\n",
            "Validation score: 0.966762\n",
            "Iteration 51, loss = 4.80319348\n",
            "Validation score: 0.967557\n",
            "Iteration 52, loss = 4.64391970\n",
            "Validation score: 0.967954\n",
            "Iteration 53, loss = 4.48708395\n",
            "Validation score: 0.968238\n",
            "Iteration 54, loss = 4.29662289\n",
            "Validation score: 0.968839\n",
            "Iteration 55, loss = 4.16437208\n",
            "Validation score: 0.969325\n",
            "Iteration 56, loss = 4.01587193\n",
            "Validation score: 0.969699\n",
            "Iteration 57, loss = 3.88660198\n",
            "Validation score: 0.970118\n",
            "Iteration 58, loss = 3.73902626\n",
            "Validation score: 0.970682\n",
            "Iteration 59, loss = 3.63794923\n",
            "Validation score: 0.970924\n",
            "Iteration 60, loss = 3.50290068\n",
            "Validation score: 0.971439\n",
            "Iteration 61, loss = 3.42871903\n",
            "Validation score: 0.971632\n",
            "Iteration 62, loss = 3.29997522\n",
            "Validation score: 0.971963\n",
            "Iteration 63, loss = 3.20416952\n",
            "Validation score: 0.972481\n",
            "Iteration 64, loss = 3.09166407\n",
            "Validation score: 0.972963\n",
            "Iteration 65, loss = 3.03850726\n",
            "Validation score: 0.973001\n",
            "Iteration 66, loss = 2.91244638\n",
            "Validation score: 0.973340\n",
            "Iteration 67, loss = 2.83424329\n",
            "Validation score: 0.973579\n",
            "Iteration 68, loss = 2.77344709\n",
            "Validation score: 0.973415\n",
            "Iteration 69, loss = 2.67484096\n",
            "Validation score: 0.974297\n",
            "Iteration 70, loss = 2.60287317\n",
            "Validation score: 0.974292\n",
            "Iteration 71, loss = 2.53970195\n",
            "Validation score: 0.974343\n",
            "Iteration 72, loss = 2.48243301\n",
            "Validation score: 0.974699\n",
            "Iteration 73, loss = 2.41152609\n",
            "Validation score: 0.974721\n",
            "Iteration 74, loss = 2.33146000\n",
            "Validation score: 0.975409\n",
            "Iteration 75, loss = 2.28314534\n",
            "Validation score: 0.975527\n",
            "Iteration 76, loss = 2.22299095\n",
            "Validation score: 0.975532\n",
            "Iteration 77, loss = 2.17781416\n",
            "Validation score: 0.975898\n",
            "Iteration 78, loss = 2.11897846\n",
            "Validation score: 0.975891\n",
            "Iteration 79, loss = 2.06008839\n",
            "Validation score: 0.976320\n",
            "Iteration 80, loss = 2.02092996\n",
            "Validation score: 0.976488\n",
            "Iteration 81, loss = 1.97030331\n",
            "Validation score: 0.976428\n",
            "Iteration 82, loss = 1.95259835\n",
            "Validation score: 0.976706\n",
            "Iteration 83, loss = 1.88169269\n",
            "Validation score: 0.976990\n",
            "Iteration 84, loss = 1.83761718\n",
            "Validation score: 0.977034\n",
            "Iteration 85, loss = 1.79402030\n",
            "Validation score: 0.977224\n",
            "Iteration 86, loss = 1.74762431\n",
            "Validation score: 0.977197\n",
            "Iteration 87, loss = 1.70633772\n",
            "Validation score: 0.977468\n",
            "Iteration 88, loss = 1.65814607\n",
            "Validation score: 0.977495\n",
            "Iteration 89, loss = 1.62417992\n",
            "Validation score: 0.977681\n",
            "Iteration 90, loss = 1.59065525\n",
            "Validation score: 0.977874\n",
            "Iteration 91, loss = 1.56335920\n",
            "Validation score: 0.978031\n",
            "Iteration 92, loss = 1.52021116\n",
            "Validation score: 0.978166\n",
            "Iteration 93, loss = 1.47702371\n",
            "Validation score: 0.978277\n",
            "Iteration 94, loss = 1.44794051\n",
            "Validation score: 0.978243\n",
            "Iteration 95, loss = 1.41298236\n",
            "Validation score: 0.978399\n",
            "Iteration 96, loss = 1.37855075\n",
            "Validation score: 0.978554\n",
            "Iteration 97, loss = 1.34564076\n",
            "Validation score: 0.978782\n",
            "Iteration 98, loss = 1.32725743\n",
            "Validation score: 0.978592\n",
            "Iteration 99, loss = 1.29184454\n",
            "Validation score: 0.978834\n",
            "Iteration 100, loss = 1.26780047\n",
            "Validation score: 0.979024\n",
            "Iteration 101, loss = 1.23383058\n",
            "Validation score: 0.979031\n",
            "Iteration 102, loss = 1.21461731\n",
            "Validation score: 0.979027\n",
            "Iteration 103, loss = 1.18961485\n",
            "Validation score: 0.979392\n",
            "Iteration 104, loss = 1.15674083\n",
            "Validation score: 0.979299\n",
            "Iteration 105, loss = 1.13045721\n",
            "Validation score: 0.979324\n",
            "Iteration 106, loss = 1.10787754\n",
            "Validation score: 0.979427\n",
            "Iteration 107, loss = 1.08357972\n",
            "Validation score: 0.979567\n",
            "Iteration 108, loss = 1.05945810\n",
            "Validation score: 0.979608\n",
            "Iteration 109, loss = 1.03564550\n",
            "Validation score: 0.979667\n",
            "Iteration 110, loss = 1.00979052\n",
            "Validation score: 0.979671\n",
            "Iteration 111, loss = 0.98522201\n",
            "Validation score: 0.980014\n",
            "Iteration 112, loss = 0.96948260\n",
            "Validation score: 0.980016\n",
            "Iteration 113, loss = 0.94400019\n",
            "Validation score: 0.980004\n",
            "Iteration 114, loss = 0.92457356\n",
            "Validation score: 0.980134\n",
            "Iteration 115, loss = 0.90810425\n",
            "Validation score: 0.980086\n",
            "Iteration 116, loss = 0.89040206\n",
            "Validation score: 0.980149\n",
            "Iteration 117, loss = 0.87208552\n",
            "Validation score: 0.980265\n",
            "Iteration 118, loss = 0.85261514\n",
            "Validation score: 0.980415\n",
            "Iteration 119, loss = 0.83254396\n",
            "Validation score: 0.980386\n",
            "Iteration 120, loss = 0.81299523\n",
            "Validation score: 0.980513\n",
            "Iteration 121, loss = 0.80299658\n",
            "Validation score: 0.980547\n",
            "Iteration 122, loss = 0.78551978\n",
            "Validation score: 0.980483\n",
            "Iteration 123, loss = 0.76561686\n",
            "Validation score: 0.980678\n",
            "Iteration 124, loss = 0.75834389\n",
            "Validation score: 0.980709\n",
            "Iteration 125, loss = 0.73110697\n",
            "Validation score: 0.980726\n",
            "Iteration 126, loss = 0.71935317\n",
            "Validation score: 0.980818\n",
            "Iteration 127, loss = 0.70079540\n",
            "Validation score: 0.980899\n",
            "Iteration 128, loss = 0.68357067\n",
            "Validation score: 0.980888\n",
            "Iteration 129, loss = 0.67661589\n",
            "Validation score: 0.981033\n",
            "Iteration 130, loss = 0.66708054\n",
            "Validation score: 0.980953\n",
            "Iteration 131, loss = 0.64928048\n",
            "Validation score: 0.981138\n",
            "Iteration 132, loss = 0.63689942\n",
            "Validation score: 0.981124\n",
            "Iteration 133, loss = 0.62694612\n",
            "Validation score: 0.981332\n",
            "Iteration 134, loss = 0.61185771\n",
            "Validation score: 0.981177\n",
            "Iteration 135, loss = 0.60033327\n",
            "Validation score: 0.981301\n",
            "Iteration 136, loss = 0.58749467\n",
            "Validation score: 0.981319\n",
            "Iteration 137, loss = 0.57062406\n",
            "Validation score: 0.981586\n",
            "Iteration 138, loss = 0.55880714\n",
            "Validation score: 0.981488\n",
            "Iteration 139, loss = 0.54199117\n",
            "Validation score: 0.981481\n",
            "Iteration 140, loss = 0.53176752\n",
            "Validation score: 0.981615\n",
            "Iteration 141, loss = 0.52149276\n",
            "Validation score: 0.981578\n",
            "Iteration 142, loss = 0.50900329\n",
            "Validation score: 0.981641\n",
            "Iteration 143, loss = 0.50974165\n",
            "Validation score: 0.981590\n",
            "Iteration 144, loss = 0.49039325\n",
            "Validation score: 0.981688\n",
            "Iteration 145, loss = 0.48030508\n",
            "Validation score: 0.981752\n",
            "Iteration 146, loss = 0.47871839\n",
            "Validation score: 0.981794\n",
            "Iteration 147, loss = 0.46767393\n",
            "Validation score: 0.981848\n",
            "Iteration 148, loss = 0.45730484\n",
            "Validation score: 0.981825\n",
            "Iteration 149, loss = 0.45443309\n",
            "Validation score: 0.982031\n",
            "Iteration 150, loss = 0.43516635\n",
            "Validation score: 0.981943\n",
            "Iteration 151, loss = 0.43179764\n",
            "Validation score: 0.981994\n",
            "Iteration 152, loss = 0.42080014\n",
            "Validation score: 0.982046\n",
            "Iteration 153, loss = 0.40916249\n",
            "Validation score: 0.982140\n",
            "Iteration 154, loss = 0.40675997\n",
            "Validation score: 0.982215\n",
            "Iteration 155, loss = 0.39450612\n",
            "Validation score: 0.982192\n",
            "Iteration 156, loss = 0.38271552\n",
            "Validation score: 0.982219\n",
            "Iteration 157, loss = 0.37781517\n",
            "Validation score: 0.982316\n",
            "Iteration 158, loss = 0.37062224\n",
            "Validation score: 0.982305\n",
            "Iteration 159, loss = 0.36497074\n",
            "Validation score: 0.982361\n",
            "Iteration 160, loss = 0.35203177\n",
            "Validation score: 0.982364\n",
            "Iteration 161, loss = 0.34230971\n",
            "Validation score: 0.982427\n",
            "Iteration 162, loss = 0.33644720\n",
            "Validation score: 0.982511\n",
            "Iteration 163, loss = 0.33249548\n",
            "Validation score: 0.982599\n",
            "Iteration 164, loss = 0.32957060\n",
            "Validation score: 0.982589\n",
            "Iteration 165, loss = 0.32026012\n",
            "Validation score: 0.982588\n",
            "Iteration 166, loss = 0.31177044\n",
            "Validation score: 0.982644\n",
            "Iteration 167, loss = 0.30909179\n",
            "Validation score: 0.982677\n",
            "Iteration 168, loss = 0.30251045\n",
            "Validation score: 0.982684\n",
            "Iteration 169, loss = 0.29757107\n",
            "Validation score: 0.982624\n",
            "Iteration 170, loss = 0.30005861\n",
            "Validation score: 0.982819\n",
            "Iteration 171, loss = 0.28900451\n",
            "Validation score: 0.982805\n",
            "Iteration 172, loss = 0.28923885\n",
            "Validation score: 0.982832\n",
            "Iteration 173, loss = 0.27420455\n",
            "Validation score: 0.982866\n",
            "Iteration 174, loss = 0.27191566\n",
            "Validation score: 0.982885\n",
            "Iteration 175, loss = 0.25822911\n",
            "Validation score: 0.983043\n",
            "Iteration 176, loss = 0.25833447\n",
            "Validation score: 0.982915\n",
            "Iteration 177, loss = 0.24850095\n",
            "Validation score: 0.983039\n",
            "Iteration 178, loss = 0.24352175\n",
            "Validation score: 0.983033\n",
            "Iteration 179, loss = 0.23586225\n",
            "Validation score: 0.982974\n",
            "Iteration 180, loss = 0.23293394\n",
            "Validation score: 0.983060\n",
            "Iteration 181, loss = 0.23017471\n",
            "Validation score: 0.983037\n",
            "Iteration 182, loss = 0.22236771\n",
            "Validation score: 0.983052\n",
            "Iteration 183, loss = 0.21918014\n",
            "Validation score: 0.983087\n",
            "Iteration 184, loss = 0.21657704\n",
            "Validation score: 0.983138\n",
            "Iteration 185, loss = 0.21235478\n",
            "Validation score: 0.983240\n",
            "Iteration 186, loss = 0.20969595\n",
            "Validation score: 0.983127\n",
            "Iteration 187, loss = 0.20530514\n",
            "Validation score: 0.983245\n",
            "Iteration 188, loss = 0.19780609\n",
            "Validation score: 0.983209\n",
            "Iteration 189, loss = 0.19397356\n",
            "Validation score: 0.983284\n",
            "Iteration 190, loss = 0.19006019\n",
            "Validation score: 0.983253\n",
            "Iteration 191, loss = 0.18612938\n",
            "Validation score: 0.983356\n",
            "Iteration 192, loss = 0.18482669\n",
            "Validation score: 0.983282\n",
            "Iteration 193, loss = 0.18653584\n",
            "Validation score: 0.983302\n",
            "Iteration 194, loss = 0.17691768\n",
            "Validation score: 0.983381\n",
            "Iteration 195, loss = 0.17188546\n",
            "Validation score: 0.983385\n",
            "Iteration 196, loss = 0.17100865\n",
            "Validation score: 0.983389\n",
            "Iteration 197, loss = 0.16844633\n",
            "Validation score: 0.983451\n",
            "Iteration 198, loss = 0.16255489\n",
            "Validation score: 0.983475\n",
            "Iteration 199, loss = 0.15967977\n",
            "Validation score: 0.983535\n",
            "Iteration 200, loss = 0.15602547\n",
            "Validation score: 0.983416\n",
            "Iteration 201, loss = 0.15260149\n",
            "Validation score: 0.983646\n",
            "Iteration 202, loss = 0.15035283\n",
            "Validation score: 0.983474\n",
            "Iteration 203, loss = 0.14623254\n",
            "Validation score: 0.983584\n",
            "Iteration 204, loss = 0.14413668\n",
            "Validation score: 0.983559\n",
            "Iteration 205, loss = 0.14266885\n",
            "Validation score: 0.983575\n",
            "Iteration 206, loss = 0.13719790\n",
            "Validation score: 0.983621\n",
            "Iteration 207, loss = 0.13527621\n",
            "Validation score: 0.983596\n",
            "Iteration 208, loss = 0.13372722\n",
            "Validation score: 0.983740\n",
            "Iteration 209, loss = 0.12863036\n",
            "Validation score: 0.983644\n",
            "Iteration 210, loss = 0.12564070\n",
            "Validation score: 0.983760\n",
            "Iteration 211, loss = 0.12427192\n",
            "Validation score: 0.983645\n",
            "Iteration 212, loss = 0.12059055\n",
            "Validation score: 0.983786\n",
            "Iteration 213, loss = 0.11913163\n",
            "Validation score: 0.983731\n",
            "Iteration 214, loss = 0.11698852\n",
            "Validation score: 0.983822\n",
            "Iteration 215, loss = 0.11302316\n",
            "Validation score: 0.983736\n",
            "Iteration 216, loss = 0.11081549\n",
            "Validation score: 0.983820\n",
            "Iteration 217, loss = 0.10830535\n",
            "Validation score: 0.983813\n",
            "Iteration 218, loss = 0.10535471\n",
            "Validation score: 0.983862\n",
            "Iteration 219, loss = 0.10333474\n",
            "Validation score: 0.983863\n",
            "Iteration 220, loss = 0.10145011\n",
            "Validation score: 0.983918\n",
            "Iteration 221, loss = 0.10175101\n",
            "Validation score: 0.983883\n",
            "Iteration 222, loss = 0.09877072\n",
            "Validation score: 0.983889\n",
            "Validation score did not improve more than tol=0.000100 for 20 consecutive epochs. Stopping.\n",
            "âœ… Validation RMSE: 3.617909769764064\n",
            "ðŸŽ‰ submission.csv saved!\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# ðŸš€ MLPRegressor (Neural Network) for Regression\n",
        "# ==========================================\n",
        "import pandas as pd\n",
        "import numpy as np   # âœ… needed for sqrt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Load data\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "# 2. Features & target\n",
        "target_col = \"target\"   # change if your target column name is different\n",
        "id_col = \"id\"           # change if ID column is different\n",
        "\n",
        "X = train.drop(columns=[target_col])\n",
        "y = train[target_col]\n",
        "\n",
        "# Drop ID column from test before scaling\n",
        "if id_col in test.columns:\n",
        "    test = test.drop(columns=[id_col])\n",
        "\n",
        "# 3. Scale features (MLP needs normalized input)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# 4. Train/Validation split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 5. Define MLPRegressor\n",
        "mlp = MLPRegressor(\n",
        "    hidden_layer_sizes=(256, 128, 64),   # 3 hidden layers\n",
        "    activation=\"relu\",\n",
        "    solver=\"adam\",\n",
        "    learning_rate_init=0.001,\n",
        "    max_iter=500,\n",
        "    random_state=42,\n",
        "    early_stopping=True,  # âœ… built-in early stopping\n",
        "    n_iter_no_change=20,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 6. Train\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# 7. Validation check\n",
        "valid_pred = mlp.predict(X_valid)\n",
        "mse = mean_squared_error(y_valid, valid_pred)\n",
        "rmse = np.sqrt(mse)   # âœ… manual RMSE\n",
        "print(\"âœ… Validation RMSE:\", rmse)\n",
        "\n",
        "# 8. Predict on test set\n",
        "test_pred = mlp.predict(test_scaled)\n",
        "\n",
        "# 9. Save submission\n",
        "submission = sample_submission.copy()\n",
        "submission[submission.columns[-1]] = test_pred\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"ðŸŽ‰ submission.csv saved!\")\n"
      ]
    }
  ]
}